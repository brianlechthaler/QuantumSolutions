{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving the Knapsack Problem with Quantum\n",
    "In this notebook we take on the challenge of solving a common constraint satisfaction problem known as the knapsack problem.\n",
    "\n",
    "* Hardware: D-Wave Advantage System version 1.1\n",
    "* Provider: Amazon Web Services Braket\n",
    "\n",
    "notebook by [Brian Lechthaler](https://github.com/brianlechthaler) | gnu gpl v3 | 2020-12-15 | please don't distribute without explicit written consent and/or giving attribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Introduction\n",
    "### 1.0: Shipping Fruit\n",
    "Let's imagine for a moment that we are farmers who export their fruit to other countries. We have 4 fruits to ship abroad: grapes, apples, bananas and pears. Each item, as shown in the figure below, is packaged in a large box to then be packed into a standard shipping container."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://storage.googleapis.com/jupyter_assets-463b/knapsack_fruits.svg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 The Problem\n",
    "There's plenty of room in the shipping container to fit as many boxes as we need, but due to the weight limits of shipping containers and the vehicles used to transport them we can only store so many boxes of each fruit before hitting weight limits. \n",
    "\n",
    "What's the most profitable way can we fill our container without exceeding weight limits while also exceeding weight limits?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://storage.googleapis.com/jupyter_assets-463b/knapsack_shippingContainer.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2: The Solution\n",
    "This problem that we are faced with is characteristic of the exact kind of problem Quantum Annealers excel at: it's a constraint solution problem that can be expressed as a Binary Quadratic Model, or BQM for short. \n",
    "\n",
    "### 1.3: Technical Overview of Solution\n",
    "This notebook starts by generating a BQM from input variables. Then, a sampler and EmbeddingComposite() is created for our D-Wave machine on AWS. We then send a request over to our D-Wave machine that queues our BQM as a new job and runs it as soon as there is availibility. Once our BQM is on the QPU, it gets solved very quickly (nanoseconds to milliseconds) and returned back to us. Even after we test the limits and scale until we can't anymore, it still only takes a fraction of a fraction of a second to run. This is the magic of quantum: solving large scale equations with many variables in quadratic time, as opposed to linear or even logarithmic time for a classical computer performing the same operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull the original example to get the datasets. Comment this out if you don't need it.\n",
    "!git clone https://github.com/dwave-examples/knapsack.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qq autopep8\n",
    "!pip install -qq jupyter_contrib_nbextensions==0.5.1\n",
    "!pip install -qq bokeh==0.12.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"be304f3c-d58f-4959-a005-139ff5838802\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id !== undefined) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var element_id = msg.content.text.trim();\n",
       "            Bokeh.index[element_id].model.document.clear();\n",
       "            delete Bokeh.index[element_id];\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"be304f3c-d58f-4959-a005-139ff5838802\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"be304f3c-d58f-4959-a005-139ff5838802\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'be304f3c-d58f-4959-a005-139ff5838802' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.15.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.15.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.15.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.15.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.15.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.15.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.15.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.15.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.15.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.15.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"be304f3c-d58f-4959-a005-139ff5838802\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"be304f3c-d58f-4959-a005-139ff5838802\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"be304f3c-d58f-4959-a005-139ff5838802\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'be304f3c-d58f-4959-a005-139ff5838802' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.15.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.15.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.15.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.15.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.15.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.15.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.15.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.15.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.15.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.15.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"be304f3c-d58f-4959-a005-139ff5838802\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import itertools\n",
    "from itertools import combinations\n",
    "from dwave.system.composites import EmbeddingComposite\n",
    "from braket.ocean_plugin import BraketSampler, BraketDWaveSampler\n",
    "import time\n",
    "from datetime import datetime as dt\n",
    "from helpers.embedding import embeddings\n",
    "import pandas as pd\n",
    "import dimod\n",
    "from math import log2, floor\n",
    "from bucket import get_bucket as bucket\n",
    "import draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook specific config\n",
    "dwave_qpu = 'Advantage_system1'\n",
    "notebook_start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AWS specific config\n",
    "# Please enter the S3 bucket you created during onboarding in the code below\n",
    "my_bucket = bucket() # the name of the bucket\n",
    "my_prefix = \"results\" # the name of the folder in the bucket\n",
    "s3_folder = (my_bucket, my_prefix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Defining Functions\n",
    "### 3.0: Timestamper\n",
    "This is a helpful function to quickly add a timestamp to the output of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsmsg(msg=None):\n",
    "    now = dt.now()\n",
    "    timestamp = f'[@{str(now)}]: '\n",
    "    message = timestamp + msg\n",
    "    return message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1: Sampler Builder\n",
    "This function creates our sampler along with an EmbeddingComposite() for the sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mksampler():\n",
    "    arn = 'arn:aws:braket:::device/qpu/d-wave/' + dwave_qpu\n",
    "    print(tsmsg(f'Building sampler from {arn}...'))\n",
    "    sampler = BraketDWaveSampler(s3_folder, arn)\n",
    "    print(tsmsg(f'BraketDWaveSampler successfully built for {dwave_qpu} on AWS Braket.\\n    -> Building EmbeddingComposite for sampler...'))\n",
    "    sampler = EmbeddingComposite(sampler)\n",
    "    print(tsmsg(f'EmbeddingComposite() successfully built.\\n    -> Returning sampler.'))\n",
    "    return sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2: Sampler Runner\n",
    "This function is responsible for sending the BQM to the D-Wave machine for solving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runSampler(bqm):\n",
    "    x = '\\n    -> '\n",
    "    print(tsmsg('Building sampler...'))\n",
    "    sampler = mksampler()\n",
    "    print(tsmsg(f\"[CLASSIC->QUANTUM] Creating a job to anneal on {dwave_qpu}'s QPU, and awaiting results...\"))\n",
    "    sampStart = time.time()\n",
    "    sampleset = sampler.sample(bqm)\n",
    "    sampEnd = time.time()\n",
    "    sampDelta = sampEnd - sampStart\n",
    "    print(tsmsg(f\"[QUANTUM->CLASSIC] Annealing completed successfully.{x}{sampDelta} seconds have elapsed since we sent our job to {dwave_qpu}.{x}Returning results from from {dwave_qpu}'s QPU.\"))\n",
    "    sample = sampleset.first.sample\n",
    "    energy = sampleset.first.energy\n",
    "    return sampleset, sample, energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3: Knapsack Builder\n",
    "This function converts our costs, weights, and the maximum weight we can carry into a BQM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_knapsack_bqm(costs, weights, weight_capacity):\n",
    "    x = '\\n    -> '\n",
    "    \"\"\"Construct BQM for the knapsack problem\n",
    "    \n",
    "    Args:\n",
    "        costs (array-like):\n",
    "            Array of costs associated with the items\n",
    "        weights (array-like):\n",
    "            Array of weights associated with the items\n",
    "        weight_capacity (int):\n",
    "            Maximum allowable weight\n",
    "    \n",
    "    Returns:\n",
    "        Binary quadratic model instance\n",
    "    \"\"\"\n",
    "    print(tsmsg('Building BQM.'))\n",
    "    buildbqmstart = time.time()\n",
    "    # Initialize BQM - use large-capacity BQM so that the problem can be\n",
    "    # scaled by the user.\n",
    "    bqm = dimod.AdjVectorBQM(dimod.Vartype.BINARY)\n",
    "\n",
    "    # Lagrangian multiplier\n",
    "    # First guess as suggested in Lucas's paper\n",
    "    lagrange = max(costs)\n",
    "\n",
    "    # Number of objects\n",
    "    x_size = len(costs)\n",
    "\n",
    "    # Lucas's algorithm introduces additional slack variables to\n",
    "    # handle the inequality. M+1 binary slack variables are needed to\n",
    "    # represent the sum using a set of powers of 2.\n",
    "    M = floor(log2(weight_capacity))\n",
    "    num_slack_variables = M + 1\n",
    "\n",
    "    # Slack variable list for Lucas's algorithm. The last variable has\n",
    "    # a special value because it terminates the sequence.\n",
    "    y = [2**n for n in range(M)]\n",
    "    y.append(weight_capacity + 1 - 2**M)\n",
    "\n",
    "    # Hamiltonian xi-xi terms\n",
    "    for k in range(x_size):\n",
    "        bqm.set_linear('x' + str(k), lagrange * (weights[k]**2) - costs[k])\n",
    "\n",
    "    # Hamiltonian xi-xj terms\n",
    "    for i in range(x_size):\n",
    "        for j in range(i + 1, x_size):\n",
    "            key = ('x' + str(i), 'x' + str(j))\n",
    "            bqm.quadratic[key] = 2 * lagrange * weights[i] * weights[j]\n",
    "\n",
    "    # Hamiltonian y-y terms\n",
    "    for k in range(num_slack_variables):\n",
    "        bqm.set_linear('y' + str(k), lagrange * (y[k]**2))\n",
    "\n",
    "    # Hamiltonian yi-yj terms\n",
    "    for i in range(num_slack_variables):\n",
    "        for j in range(i + 1, num_slack_variables):\n",
    "            key = ('y' + str(i), 'y' + str(j))\n",
    "            bqm.quadratic[key] = 2 * lagrange * y[i] * y[j]\n",
    "\n",
    "    # Hamiltonian x-y terms\n",
    "    for i in range(x_size):\n",
    "        for j in range(num_slack_variables):\n",
    "            key = ('x' + str(i), 'y' + str(j))\n",
    "            bqm.quadratic[key] = -2 * lagrange * weights[i] * y[j]\n",
    "    buildbqmend = time.time()\n",
    "    buildbqmdelta = buildbqmend - buildbqmstart\n",
    "    print(tsmsg(f'Done.{x} BQM built in {buildbqmdelta} seconds.'))\n",
    "    return bqm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4: Compile the BQM\n",
    "This function uses the logic we just defined to create a BQM to be solved on our D-Wave machine, and time how long it takes to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compileBQM(costs, weights, weight_capacity):\n",
    "    #Build knapsack problem from costs, weights, and max capacity\n",
    "    x = '\\n    -> '\n",
    "    print(tsmsg(f\"Compiling BQM with: {x}Input Costs: {costs}{x}Weights: {weights}{x}Max Weight: {weight_capacity}\"))\n",
    "    bqmstart = time.time()\n",
    "    bqm = build_knapsack_bqm(costs, weights, weight_capacity)\n",
    "    bqmend = time.time()\n",
    "    bqmdelta = bqmend - bqmstart\n",
    "    print(tsmsg(f\"BQM compiled in {bqmdelta} seconds.\"))\n",
    "    return bqm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5: Solve BQM\n",
    "Now that we have our BQM all we have to do is send it to our D-Wave quantum annealer and wait for the response, then we decide whether the result is valid, run again if it isn't and finally return the valid solution when we are done. Note the valid solution verification step at the end, this kind of error handling is vital to building good quantum solutions: because at the end of the day we're relying on quantum physics to run calculations for production workloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_knapsack():\n",
    "    return None\n",
    "def solve_knapsack(costs, weights, weight_capacity, sampler=None, xdf=pd.DataFrame()):\n",
    "    \"\"\"Construct BQM and solve the knapsack problem\n",
    "    \n",
    "    Args:\n",
    "        costs (array-like):\n",
    "            Array of costs associated with the items\n",
    "        weights (array-like):\n",
    "            Array of weights associated with the items\n",
    "        weight_capacity (int):\n",
    "            Maximum allowable weight\n",
    "        sampler (BQM sampler instance or None):\n",
    "            A BQM sampler instance or None, in which case\n",
    "            LeapHybridSampler is used by default\n",
    "    \n",
    "    Returns:\n",
    "        Tuple:\n",
    "            List of indices of selected items\n",
    "            Solution energy\n",
    "    \"\"\"\n",
    "    original_costs = costs\n",
    "    original_weights = weights\n",
    "    original_weightcap = weight_capacity\n",
    "    # compile a BQM from input variables\n",
    "    bqm = compileBQM(costs, weights, weight_capacity)\n",
    "    \n",
    "    # run the sampler and read the results into 3 variables\n",
    "    sampleset, sample, energy = runSampler(bqm)\n",
    "\n",
    "    # Build solution from returned binary variables:\n",
    "    selected_item_indices = []\n",
    "    for varname, value in sample.items():\n",
    "        # For each \"x\" variable, check whether its value is set, which\n",
    "        # indicates that the corresponding item is included in the\n",
    "        # knapsack\n",
    "        if value and varname.startswith('x'):\n",
    "            # The index into the weight array is retrieved from the\n",
    "            # variable name\n",
    "            selected_item_indices.append(int(varname[1:]))\n",
    "    selected_weights = list(xdf.loc[selected_item_indices, 'weight'])\n",
    "    total_weight = sum(selected_weights)\n",
    "    if total_weight > original_weightcap:\n",
    "        print(tsmsg('ERROR: Invalid solution, total weight exceeds specified capacity. Attempting to try again.'))\n",
    "        solve_knapsack(original_costs, original_weights, original_weightcap, sampler, xdf=xdf)\n",
    "    else:\n",
    "        print(tsmsg(''))\n",
    "    return sorted(selected_item_indices), energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6: Tying it all Together (Main Function)\n",
    "Finally, we take all the pieces we just defined and put them together to make our main function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knapsackSolver(wt_cap=None, pth=None):\n",
    "    \n",
    "    # set defaults just in case\n",
    "    if wt_cap == None:\n",
    "        wt_cap = 50\n",
    "    if pth == None:\n",
    "        pth = 'knapsack/data/small.csv'\n",
    "\n",
    "    # parse input data\n",
    "    print(tsmsg(f'Reading the contents of file {pth} into a new Pandas DataFrame.'))\n",
    "    csvreadstart = time.time()\n",
    "    df = pd.read_csv(pth, names=['cost', 'weight'])\n",
    "    csvreadstop = time.time()\n",
    "    csvreaddelta = csvreadstop - csvreadstart\n",
    "    print(tsmsg(f'New dataframe created from file {pth} in {csvreaddelta} seconds.'))\n",
    "\n",
    "    selected_item_indices, energy = solve_knapsack(df['cost'], df['weight'], wt_cap, xdf=df)\n",
    "    selected_weights = list(df.loc[selected_item_indices,'weight'])\n",
    "    selected_costs = list(df.loc[selected_item_indices,'cost'])\n",
    "    energysummary = \"----> SOLUTION: Found solution at energy {}\".format(energy)\n",
    "    print(tsmsg(energysummary))\n",
    "    itemsummary = \"----> SOLUTION: Selected item numbers (0-indexed): \" + str(selected_item_indices)\n",
    "    print(tsmsg(itemsummary))\n",
    "    weightsummary = \"----> SOLUTION: Selected item weights: {}, total = {}\".format(selected_weights, sum(selected_weights))\n",
    "    print(tsmsg(weightsummary))\n",
    "    costsummary = \"----> SOLUTION: Selected item costs: {}, total = {}\".format(selected_costs, sum(selected_costs))\n",
    "    print(tsmsg(costsummary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Testing & Results!\n",
    "### 4.0: First Test\n",
    "For our first test run, we try a max weight of 50 with the \"small\" dataset. As expected, the D-Wave Annealer has absolutely no problem solving this problem in nanoseconds-to-milliseconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[@2020-12-16 00:21:55.396850]: Reading the contents of file knapsack/data/small.csv into a new Pandas DataFrame.\n",
      "[@2020-12-16 00:21:55.401228]: New dataframe created from file knapsack/data/small.csv in 0.0038251876831054688 seconds.\n",
      "[@2020-12-16 00:21:55.402040]: Compiling BQM with: \n",
      "    -> Input Costs: 0    35\n",
      "1    85\n",
      "2    30\n",
      "3    50\n",
      "4    70\n",
      "5    80\n",
      "6    55\n",
      "Name: cost, dtype: int64\n",
      "    -> Weights: 0    12\n",
      "1    27\n",
      "2    11\n",
      "3    17\n",
      "4    20\n",
      "5    10\n",
      "6    15\n",
      "Name: weight, dtype: int64\n",
      "    -> Max Weight: 50\n",
      "[@2020-12-16 00:21:55.402095]: Building BQM.\n",
      "[@2020-12-16 00:21:55.402802]: Done.\n",
      "    ->  BQM built in 0.0006716251373291016 seconds.\n",
      "[@2020-12-16 00:21:55.402845]: BQM compiled in 0.0007488727569580078 seconds.\n",
      "[@2020-12-16 00:21:55.402875]: Building sampler...\n",
      "[@2020-12-16 00:21:55.402907]: Building sampler from arn:aws:braket:::device/qpu/d-wave/Advantage_system1...\n",
      "[@2020-12-16 00:21:57.475594]: BraketDWaveSampler successfully built for Advantage_system1 on AWS Braket.\n",
      "    -> Building EmbeddingComposite for sampler...\n",
      "[@2020-12-16 00:21:57.982102]: EmbeddingComposite() successfully built.\n",
      "    -> Returning sampler.\n",
      "[@2020-12-16 00:21:57.982212]: [CLASSIC->QUANTUM] Creating a job to anneal on Advantage_system1's QPU, and awaiting results...\n",
      "[@2020-12-16 00:22:02.972368]: [QUANTUM->CLASSIC] Annealing completed successfully.\n",
      "    -> 4.989717960357666 seconds have elapsed since we sent our job to Advantage_system1.\n",
      "    -> Returning results from from Advantage_system1's QPU.\n",
      "[@2020-12-16 00:22:02.975009]: \n",
      "[@2020-12-16 00:22:02.976010]: ----> SOLUTION: Found solution at energy -205.0\n",
      "[@2020-12-16 00:22:02.976065]: ----> SOLUTION: Selected item numbers (0-indexed): [4, 5, 6]\n",
      "[@2020-12-16 00:22:02.976096]: ----> SOLUTION: Selected item weights: [20, 10, 15], total = 45\n",
      "[@2020-12-16 00:22:02.976585]: ----> SOLUTION: Selected item costs: [70, 80, 55], total = 205\n"
     ]
    }
   ],
   "source": [
    "knapsackSolver(50, 'knapsack/data/small.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1: Second Test\n",
    "Yet again, our annealer proves what can only be described as quantum's *complete and total ascendancy* over any model or practical example we have to describe even our wildest dreams of classical computer performance. Just imagine what the world will be able to do once we can eliminate current barriers like noise(interference), size, temperature (superconductors currently used in quantum computers need to be kept at well over 150x colder temperatures than interstellar space.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[@2020-12-16 00:22:02.982601]: Reading the contents of file knapsack/data/small.csv into a new Pandas DataFrame.\n",
      "[@2020-12-16 00:22:02.984578]: New dataframe created from file knapsack/data/small.csv in 0.0017132759094238281 seconds.\n",
      "[@2020-12-16 00:22:02.985235]: Compiling BQM with: \n",
      "    -> Input Costs: 0    35\n",
      "1    85\n",
      "2    30\n",
      "3    50\n",
      "4    70\n",
      "5    80\n",
      "6    55\n",
      "Name: cost, dtype: int64\n",
      "    -> Weights: 0    12\n",
      "1    27\n",
      "2    11\n",
      "3    17\n",
      "4    20\n",
      "5    10\n",
      "6    15\n",
      "Name: weight, dtype: int64\n",
      "    -> Max Weight: 75\n",
      "[@2020-12-16 00:22:02.985287]: Building BQM.\n",
      "[@2020-12-16 00:22:02.985999]: Done.\n",
      "    ->  BQM built in 0.0006711483001708984 seconds.\n",
      "[@2020-12-16 00:22:02.986038]: BQM compiled in 0.0007493495941162109 seconds.\n",
      "[@2020-12-16 00:22:02.986071]: Building sampler...\n",
      "[@2020-12-16 00:22:02.986098]: Building sampler from arn:aws:braket:::device/qpu/d-wave/Advantage_system1...\n",
      "[@2020-12-16 00:22:04.937097]: BraketDWaveSampler successfully built for Advantage_system1 on AWS Braket.\n",
      "    -> Building EmbeddingComposite for sampler...\n",
      "[@2020-12-16 00:22:05.432355]: EmbeddingComposite() successfully built.\n",
      "    -> Returning sampler.\n",
      "[@2020-12-16 00:22:05.432473]: [CLASSIC->QUANTUM] Creating a job to anneal on Advantage_system1's QPU, and awaiting results...\n",
      "[@2020-12-16 00:22:08.912050]: [QUANTUM->CLASSIC] Annealing completed successfully.\n",
      "    -> 3.479539394378662 seconds have elapsed since we sent our job to Advantage_system1.\n",
      "    -> Returning results from from Advantage_system1's QPU.\n",
      "[@2020-12-16 00:22:08.914785]: \n",
      "[@2020-12-16 00:22:08.916161]: ----> SOLUTION: Found solution at energy -285.0\n",
      "[@2020-12-16 00:22:08.916228]: ----> SOLUTION: Selected item numbers (0-indexed): [2, 3, 4, 5, 6]\n",
      "[@2020-12-16 00:22:08.916271]: ----> SOLUTION: Selected item weights: [11, 17, 20, 10, 15], total = 73\n",
      "[@2020-12-16 00:22:08.916299]: ----> SOLUTION: Selected item costs: [30, 50, 70, 80, 55], total = 285\n"
     ]
    }
   ],
   "source": [
    "knapsackSolver(75, 'knapsack/data/small.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Final Tests\n",
    "Sometimes when giving our annealer a problem that pushes it's limits in terms of how large the solvable problem space we encounter errors. Try scaling the datasets and see what the largest combination you can achieve is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[@2020-12-16 00:22:08.923672]: Reading the contents of file knapsack/data/small.csv into a new Pandas DataFrame.\n",
      "[@2020-12-16 00:22:08.929194]: New dataframe created from file knapsack/data/small.csv in 0.0049211978912353516 seconds.\n",
      "[@2020-12-16 00:22:08.929910]: Compiling BQM with: \n",
      "    -> Input Costs: 0    35\n",
      "1    85\n",
      "2    30\n",
      "3    50\n",
      "4    70\n",
      "5    80\n",
      "6    55\n",
      "Name: cost, dtype: int64\n",
      "    -> Weights: 0    12\n",
      "1    27\n",
      "2    11\n",
      "3    17\n",
      "4    20\n",
      "5    10\n",
      "6    15\n",
      "Name: weight, dtype: int64\n",
      "    -> Max Weight: 150\n",
      "[@2020-12-16 00:22:08.929959]: Building BQM.\n",
      "[@2020-12-16 00:22:08.931521]: Done.\n",
      "    ->  BQM built in 0.0015225410461425781 seconds.\n",
      "[@2020-12-16 00:22:08.931581]: BQM compiled in 0.0016188621520996094 seconds.\n",
      "[@2020-12-16 00:22:08.931611]: Building sampler...\n",
      "[@2020-12-16 00:22:08.931640]: Building sampler from arn:aws:braket:::device/qpu/d-wave/Advantage_system1...\n",
      "[@2020-12-16 00:22:10.932700]: BraketDWaveSampler successfully built for Advantage_system1 on AWS Braket.\n",
      "    -> Building EmbeddingComposite for sampler...\n",
      "[@2020-12-16 00:22:11.429239]: EmbeddingComposite() successfully built.\n",
      "    -> Returning sampler.\n",
      "[@2020-12-16 00:22:11.429379]: [CLASSIC->QUANTUM] Creating a job to anneal on Advantage_system1's QPU, and awaiting results...\n",
      "[@2020-12-16 00:22:17.061386]: [QUANTUM->CLASSIC] Annealing completed successfully.\n",
      "    -> 5.631957292556763 seconds have elapsed since we sent our job to Advantage_system1.\n",
      "    -> Returning results from from Advantage_system1's QPU.\n",
      "[@2020-12-16 00:22:17.064434]: \n",
      "[@2020-12-16 00:22:17.065342]: ----> SOLUTION: Found solution at energy -335.0\n",
      "[@2020-12-16 00:22:17.065673]: ----> SOLUTION: Selected item numbers (0-indexed): [0, 1, 2, 3, 5, 6]\n",
      "[@2020-12-16 00:22:17.065832]: ----> SOLUTION: Selected item weights: [12, 27, 11, 17, 10, 15], total = 92\n",
      "[@2020-12-16 00:22:17.065871]: ----> SOLUTION: Selected item costs: [35, 85, 30, 50, 80, 55], total = 335\n"
     ]
    }
   ],
   "source": [
    "knapsackSolver(150, 'knapsack/data/small.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5: Conclusions\n",
    "The knapsack problem, as with all constraint-satisfaction problems can be turned into a BQM. With our D-Wave quantum annealer, we can basically solve anything that is a BQM. By turning our problem into a BQM and solving it, we effectively exploit the dramatic speedup quantum offers for solving CSPs with large numbers of variables. The results speak for themselves. As we scale the problem up and down there are admittedly some errors we run into that are related to the actual accuracy of the machine. Over time, as quantum becomes less noisy and prone to errors, quantum computers could solve a wide range of problems at almost any scale in very small amounts of time. This massive boost in speed has the potential to usher in a new era of computing that brings use cases and solutions we could have never thought of even in our most optimistic dreams. Will they replace classical computers? Likely not, each has their advantages and weaknesses -- one cannot replace the other if one cannot be the other. Will quantum allow us to perform calculations we could not have before? Definitely. The speedup isn't just more convenient -- it makes easy work of certain problems like large prime factorisation previously thought to be impossible even for some future civilization that uses most of the universe as a classical computer to solve. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[@2020-12-16 00:22:17.073622]: Once dependencies were done importing, this notebook ran for a grand total of 21.7499098777771 seconds.\n",
      "    Notebook by Brian Lechthaler, last updated: 2020-12-16 00:22:17.073613.\n",
      "    Licensed under GNU GPL v3.\n",
      "    Do not re-distribute notebook or any of its contents without my explicit written consent and/or without attribution.\n",
      "    This notebook belongs to this repository: https://github.com/brianlechthaler/QuantumSolutions\n",
      "        If you found this useful, leave a star. Problems? Questions? Contact me or submit a pull request and I will be delighted to help you.\n"
     ]
    }
   ],
   "source": [
    "notebook_end_time = time.time()\n",
    "notebook_time_delta = notebook_end_time - notebook_start_time\n",
    "print(tsmsg(f'Once dependencies were done importing, this notebook ran for a grand total of {notebook_time_delta} seconds.\\n    Notebook by Brian Lechthaler, last updated: {str(dt.now())}.\\n    Licensed under GNU GPL v3.\\n    Do not re-distribute notebook or any of its contents without my explicit written consent and/or without attribution.\\n    This notebook belongs to this repository: https://github.com/brianlechthaler/QuantumSolutions\\n        If you found this useful, leave a star. Problems? Questions? Contact me or submit a pull request and I will be delighted to help you.'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_braket",
   "language": "python",
   "name": "conda_braket"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
